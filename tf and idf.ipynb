{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "para=\"\"\" India must stand up to the world. Because I believe that unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand. My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material. I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. I see four milestones in my career:\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\work\\natural language processing\\tf and idf.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/natural%20language%20processing/tf%20and%20idf.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m corpus\u001b[39m=\u001b[39m[]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/natural%20language%20processing/tf%20and%20idf.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sentences)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/work/natural%20language%20processing/tf%20and%20idf.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     review \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^a-zA-Z]\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m,para[\u001b[39m\"\u001b[39;49m\u001b[39mReview\u001b[39;49m\u001b[39m\"\u001b[39;49m][i])\u001b[39m# this to replace all the non alphabat ie. number, punch mark ,etc replace by space\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/natural%20language%20processing/tf%20and%20idf.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     review \u001b[39m=\u001b[39m review\u001b[39m.\u001b[39mlower()\u001b[39m# this  line is to convert the text into lower case \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/work/natural%20language%20processing/tf%20and%20idf.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     review \u001b[39m=\u001b[39m review\u001b[39m.\u001b[39msplit()\u001b[39m# this is used to split the data as we have to perform steming on the datasset \u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "wordnet=WordNetLemmatizer()\n",
    "sentences=nltk.sent_tokenize(para)\n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',para[\"Review\"][i])# this to replace all the non alphabat ie. number, punch mark ,etc replace by space\n",
    "    review = review.lower()# this  line is to convert the text into lower case \n",
    "    review = review.split()# this is used to split the data as we have to perform steming on the datasset \n",
    "    ps = PorterStemmer()\n",
    "    All_stopwords=stopwords.words('english')\n",
    "    #All_stopwords.remove('not')# if we want to analise the review of any product then not comes in the stopwords so we are excluding the not because it effects the reviews\n",
    "    review = [ps.stem(word) for word in review if not word in set(All_stopwords)]\n",
    "    review =' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
